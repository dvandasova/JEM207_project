{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing home-made libraries\n",
    "from app.scraping import scrape_accommodation_data\n",
    "from app.scraping import scrape_min_price\n",
    "from app.scraping import start_webdriver\n",
    "from app.scraping import close_webdriver\n",
    "\n",
    "from app.geos import get_coordinates\n",
    "\n",
    "from app.bundling import select_accommodation_bundles\n",
    "\n",
    "from app.input import read_excel_to_df\n",
    "from app.input import check_code\n",
    "from app.input import read_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries for geo locations\n",
    "from geopy.geocoders import Nominatim # Importing the geopy library and Nominatim class\n",
    "from geopy.exc import GeocoderTimedOut\n",
    "from geopy.distance import Distance\n",
    "from geopy.distance import geodesic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries for web scraping\n",
    "from time import sleep\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "from itertools import product\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from datetime import timedelta\n",
    "from io import BytesIO\n",
    "import requests\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing internal match data\n",
    "url = \"https://raw.githubusercontent.com/dvandasova/JEM207_project/b5414c0b6fd52309880b8478913089768dbe320e/02_Datasets/internal-data.xlsx\"\n",
    "response = requests.get(url)\n",
    "data_frame = pd.read_excel(BytesIO(response.content))\n",
    "data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'yourpath_to_the_input_txt_file'  # path to input file\n",
    "primary_code = read_code(file_path, data_frame)  # Use app.input.read_code\n",
    "print(primary_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From data_frame extract the row corresponding to the primary code\n",
    "df = data_frame.loc[data_frame.iloc[:, 0] == primary_code]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual match scraping\n",
    "### Flight and Accommodation\n",
    "The purpose of the individual scraping is to check the latest price of the selected match (different to in bulk scraping, which takes a lot of time, this individual is much faster)\n",
    "\n",
    "Please exchange the the following filepaths for your own, leading to the text file used for selecting the match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each row in the DataFrame\n",
    "min_prices = []  # To store the minimum prices for each city and date combination\n",
    "for index, row in df.iterrows():\n",
    "    city = row['flight.Code']  # Use the column name 'flight.Code' for the city\n",
    "    departure_date = row['date'].strftime('%Y-%m-%d')  # Assuming 'date' is in a proper date format\n",
    "\n",
    "    # Calculate the return date as departure date + 2 days\n",
    "    return_date = (row['date'] + timedelta(days=2)).strftime('%Y-%m-%d')\n",
    "    \n",
    "    # Scrape the minimum price for the city and date combination\n",
    "    min_price = scrape_min_price(city, departure_date, return_date)\n",
    "    \n",
    "    # Append the minimum price to the list\n",
    "    min_prices.append(min_price)\n",
    "\n",
    "    print(min_price)\n",
    "\n",
    "# Add the minimum price as a new column in the original DataFrame\n",
    "df['Min Price'] = min_prices\n",
    "\n",
    "# Display the updated DataFrame\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define lists to hold the accommodation data for each row\n",
    "accommodation_standard = []\n",
    "accommodation_superior = []\n",
    "accommodation_luxurious = []\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.maximize_window()\n",
    "\n",
    "# Loop through each row in the DataFrame to get location and dates\n",
    "for index, row in df.iterrows():\n",
    "\n",
    "    location = row['accom.Code']  # Assuming 'accom.Code' contains the location identifier\n",
    "    departure_date = row['date'].strftime('%Y-%m-%d')  # Assuming 'date' is a date column\n",
    "    return_date = (row['date'] + timedelta(days=2)).strftime('%Y-%m-%d') \n",
    "\n",
    "    city = row['city']  # Assuming 'city' contains the city name\n",
    "    \n",
    "    # Scrape accommodation data\n",
    "    accommodation_data = scrape_accommodation_data(location, departure_date, return_date)\n",
    "    accommodation_data[\"Location\"] = accommodation_data[\"Location\"] + \", \" + city\n",
    "    \n",
    "    # Filter out locations with \"Nearby - \"\n",
    "    accommodation_data = accommodation_data[~accommodation_data['Location'].str.contains(\"Nearby - \", na=False)]\n",
    "\n",
    "    current_venue = row[\"venue\"] \n",
    "\n",
    "    # Retrieve the coordinates for each accommodation\n",
    "    places = get_coordinates(accommodation_data['Location'])\n",
    "\n",
    "    # Create a DataFrame for places and coordinates\n",
    "    places_df = pd.DataFrame(places, columns=[\"Place\", \"Latitude\", \"Longitude\"])\n",
    "\n",
    "    # Geocode the current venue\n",
    "    geolocator = Nominatim(user_agent=\"Geopy Library\")\n",
    "    current_venue_location = geolocator.geocode(current_venue)\n",
    "\n",
    "    # Check if venue location was found\n",
    "    if current_venue_location:\n",
    "        base_coords = (current_venue_location.latitude, current_venue_location.longitude)\n",
    "    else:\n",
    "        base_coords = (\"Location not found\", \"Location not found\")\n",
    "\n",
    "    base_latitude = base_coords[0]\n",
    "    base_longitude = base_coords[1]\n",
    "\n",
    "    # Iterate over the places to replace \"Location not found\" with the base coordinates\n",
    "    for i, row in places_df.iterrows():\n",
    "        if row[\"Latitude\"] == \"Location not found\":\n",
    "            places_df.at[i, \"Latitude\"] = base_latitude\n",
    "            places_df.at[i, \"Longitude\"] = base_longitude\n",
    "            places_df.at[i, \"Latitude\"] = places_df.at[i, \"Latitude\"] + 0.1 \n",
    "            places_df.at[i, \"Longitude\"] = places_df.at[i, \"Longitude\"] + 0.1 \n",
    "\n",
    "\n",
    "\n",
    "    # Now places_df contains both the valid coordinates and venue coordinates for \"Location not found\"\n",
    "    # Combine this updated data back into the accommodation_data\n",
    "    accommodation_data = accommodation_data.reset_index(drop=True)\n",
    "\n",
    "    # Add latitude and longitude from places_df to accommodation_data\n",
    "    accommodation_data[\"Latitude\"] = places_df[\"Latitude\"]\n",
    "    accommodation_data[\"Longitude\"] = places_df[\"Longitude\"]\n",
    "\n",
    "    # Calculate distances between each accommodation and the venue\n",
    "    distances = []\n",
    "    for i in range(len(places_df)):\n",
    "        latitude = places_df.iloc[i][\"Latitude\"]\n",
    "        longitude = places_df.iloc[i][\"Longitude\"]\n",
    "\n",
    "        # Only calculate distance if both latitude and longitude are valid\n",
    "        if base_latitude != \"Location not found\" and latitude != \"Location not found\":\n",
    "            dist = geodesic((base_latitude, base_longitude), (latitude, longitude)).kilometers\n",
    "        else:\n",
    "            dist = float('inf')  # Assign a large distance if location is invalid\n",
    "\n",
    "        distances.append(dist)\n",
    "\n",
    "    # Add distances to accommodation_data\n",
    "    accommodation_data[\"Distance\"] = distances\n",
    "\n",
    "    # Print the accommodation data (for debugging purposes)\n",
    "    print(accommodation_data)\n",
    "\n",
    "    # Select the Standard, Superior, and Luxurious bundles\n",
    "    Standard_bundle, Superior_bundle, Luxurious_bundle = select_accommodation_bundles(accommodation_data)\n",
    "\n",
    "    # Append the accommodation names and prices to the corresponding lists\n",
    "    accommodation_standard.append({\n",
    "        'Name': Standard_bundle['Name'],\n",
    "        'Price': Standard_bundle['Price'],\n",
    "        'Rating': Standard_bundle['Rating']\n",
    "    })\n",
    "    accommodation_superior.append({\n",
    "        'Name': Superior_bundle['Name'],\n",
    "        'Price': Superior_bundle['Price'],\n",
    "        'Rating': Superior_bundle['Rating']\n",
    "    })\n",
    "    accommodation_luxurious.append({\n",
    "        'Name': Luxurious_bundle['Name'],\n",
    "        'Price': Luxurious_bundle['Price'],\n",
    "        'Rating': Luxurious_bundle['Rating']\n",
    "    })\n",
    "\n",
    "# Add the accommodation bundles to the original DataFrame\n",
    "df['Standard Accommodation'] = [x['Name'] for x in accommodation_standard]\n",
    "df['Superior Accommodation'] = [x['Name'] for x in accommodation_superior]\n",
    "df['Luxurious Accommodation'] = [x['Name'] for x in accommodation_luxurious]\n",
    "\n",
    "df['Standard Price'] = [x['Price'] for x in accommodation_standard]\n",
    "df['Superior Price'] = [x['Price'] for x in accommodation_superior]\n",
    "df['Luxurious Price'] = [x['Price'] for x in accommodation_luxurious]\n",
    "\n",
    "df['Standard Rating'] = [x['Rating'] for x in accommodation_standard]\n",
    "df['Superior Rating'] = [x['Rating'] for x in accommodation_superior]\n",
    "df['Luxurious Rating'] = [x['Rating'] for x in accommodation_luxurious]\n",
    "\n",
    "# Save the updated DataFrame with accommodation data\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SECOND PART: Visuals\n",
    "### Flight and Accommodation Pricing Trends \n",
    "The purpose of this graph is to show how much in advance is it best to book a stay to see a match. The graph contains price averages of each match day in our database.\n",
    "standard, superior, luxurious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.visuals import plot_standard\n",
    "from app.visuals import plot_superior\n",
    "from app.visuals import plot_luxurious\n",
    "from app.visuals import plot_accommodation_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the scraped data\n",
    "url = \"https://raw.githubusercontent.com/dvandasova/JEM207_project/956a3ddf3bd8e67bc692aff8e4affb00827bf5c4/full-scrape.xlsx\"\n",
    "response = requests.get(url)\n",
    "df = pd.read_excel(BytesIO(response.content))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accommodation_data = df \n",
    "accommodation_data_1 = accommodation_data[['date', 'Standard Price Total', 'Superior Price Total', 'Luxurious Price Total']]\n",
    "accommodation_data_1\n",
    "#print(accommodation_data_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data by 'date' and calculate the mean price for each accommodation type\n",
    "accommodation_data_1 = accommodation_data_1.groupby('date').mean()\n",
    "#print(accommodation_data_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consider each date as series and accomodation type as category\n",
    "# Plot a bar chart that has 3 columns for each date (accomodation type) and the height of the columns is the mean price\n",
    "plot_accommodation_data(accommodation_data_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame that contains only the 'event', 'Standard Price Total', 'Superior Price Total', and 'Luxurious Price Total' columns\n",
    "accommodation_data_2 = accommodation_data[['event', 'Standard Price Total', 'Superior Price Total', 'Luxurious Price Total']]\n",
    "#print(accommodation_data_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list, ake the 'event' column and separate it into two columns ('Home' and 'Away') separated by the ' vs. ' string\n",
    "event_list = []\n",
    "for event in accommodation_data_2['event']:\n",
    "    event_list.append(event.split(' vs. '))\n",
    "    # Appent the 'Standard Price Total', 'Superior Price Total', and 'Luxurious Price Total' columns to the list\n",
    "    event_list[-1].extend(accommodation_data_2.loc[accommodation_data_2['event'] == event, ['Standard Price Total', 'Superior Price Total', 'Luxurious Price Total']].values[0])\n",
    "#print(event_list)\n",
    "\n",
    "# Create a DataFrame from the list\n",
    "event_df = pd.DataFrame(event_list, columns=['Home', 'Away', 'Standard Price Total', 'Superior Price Total', 'Luxurious Price Total'])\n",
    "event_df = event_df.groupby(['Home', 'Away']).mean().unstack()\n",
    "#print(event_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a heatmap that shows Home team on y-axis, Away team on x-axis, and the mean price Standard accommodation as the value\n",
    "# Plot the heatmap\n",
    "plot_standard(event_df)\n",
    "\n",
    "# Create a heatmap that shows Home team on y-axis, Away team on x-axis, and the mean price Superior accommodation as the value\n",
    "# Plot the heatmap\n",
    "plot_superior(event_df)\n",
    "\n",
    "# Create a heatmap that shows Home team on y-axis, Away team on x-axis, and the mean price Luxurious accommodation as the value\n",
    "# Plot the heatmap\n",
    "plot_luxurious(event_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
